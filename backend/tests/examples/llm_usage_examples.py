"""
LLM ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„ LLM ç®¡ç†åŠŸèƒ½è¿›è¡Œä¸åŒåœºæ™¯çš„é…ç½®
"""

from agent.llm_factory import create_llm, get_shared_llm, reset_shared_llm
from graph import run_ai_research_analysis, create_research_graph


def example_1_basic_usage():
    """ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨ - ä½¿ç”¨é»˜è®¤å…±äº« LLM"""
    print("ğŸ“ ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨")

    # ç›´æ¥ä½¿ç”¨ï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨å…±äº«çš„ LLM å®ä¾‹
    result = run_ai_research_analysis('2025-12-09')
    print(f"âœ… ä½¿ç”¨é»˜è®¤ LLM å®Œæˆåˆ†æ: {result['success']}")


def example_2_custom_llm():
    """ç¤ºä¾‹ 2: ä½¿ç”¨è‡ªå®šä¹‰ LLM é…ç½®"""
    print("\nğŸ“ ç¤ºä¾‹ 2: è‡ªå®šä¹‰ LLM é…ç½®")

    # åˆ›å»ºä¿å®ˆå‹ LLMï¼ˆä½æ¸©åº¦ï¼Œæ›´ç¡®å®šæ€§çš„è¾“å‡ºï¼‰
    conservative_llm = create_llm(
        temperature=0.1,
        model="deepseek-v3-1-terminus"
    )

    # ä½¿ç”¨è‡ªå®šä¹‰ LLM è¿è¡Œåˆ†æ
    result = run_ai_research_analysis('2025-12-09', llm=conservative_llm)
    print(f"âœ… ä½¿ç”¨ä¿å®ˆå‹ LLM å®Œæˆåˆ†æ: {result['success']}")


def example_3_creative_llm():
    """ç¤ºä¾‹ 3: ä½¿ç”¨åˆ›é€ æ€§ LLM é…ç½®"""
    print("\nğŸ“ ç¤ºä¾‹ 3: åˆ›é€ æ€§ LLM é…ç½®")

    # åˆ›å»ºåˆ›é€ å‹ LLMï¼ˆé«˜æ¸©åº¦ï¼Œæ›´æœ‰åˆ›é€ æ€§çš„è¾“å‡ºï¼‰
    creative_llm = create_llm(
        temperature=0.9,
        model="deepseek-v3-1-terminus"
    )

    # ä½¿ç”¨åˆ›é€ æ€§ LLM è¿è¡Œåˆ†æ
    result = run_ai_research_analysis('2025-12-09', llm=creative_llm)
    print(f"âœ… ä½¿ç”¨åˆ›é€ å‹ LLM å®Œæˆåˆ†æ: {result['success']}")


def example_4_ab_testing():
    """ç¤ºä¾‹ 4: A/B æµ‹è¯•ä¸åŒçš„ LLM é…ç½®"""
    print("\nğŸ“ ç¤ºä¾‹ 4: A/B æµ‹è¯•ä¸åŒé…ç½®")

    # é…ç½® A: ä¿å®ˆå‹
    llm_a = create_llm(temperature=0.2)

    # é…ç½® B: å¹³è¡¡å‹
    llm_b = create_llm(temperature=0.6)

    # åˆ†åˆ«æµ‹è¯•ä¸¤ç§é…ç½®
    result_a = run_ai_research_analysis('2025-12-09', llm=llm_a)
    result_b = run_ai_research_analysis('2025-12-09', llm=llm_b)

    print(f"âœ… é…ç½® A (ä¿å®ˆå‹) ç»“æœ: {result_a['success']}")
    print(f"âœ… é…ç½® B (å¹³è¡¡å‹) ç»“æœ: {result_b['success']}")

    # æ¯”è¾ƒç»“æœ
    if result_a['success'] and result_b['success']:
        len_a = len(result_a['result'].get('strategist_thinking', ''))
        len_b = len(result_b['result'].get('strategist_thinking', ''))
        print(f"ğŸ“Š ç­–ç•¥å¸ˆæ€è€ƒé•¿åº¦å¯¹æ¯”: A={len_a}, B={len_b}")


def example_5_shared_llm_management():
    """ç¤ºä¾‹ 5: å…±äº« LLM å®ä¾‹ç®¡ç†"""
    print("\nğŸ“ ç¤ºä¾‹ 5: å…±äº« LLM ç®¡ç†")

    # è·å–å…±äº«å®ä¾‹
    shared_llm_1 = get_shared_llm()
    shared_llm_2 = get_shared_llm()

    print(f"âœ… å…±äº«å®ä¾‹æ˜¯åŒä¸€ä¸ªå¯¹è±¡: {shared_llm_1 is shared_llm_2}")

    # é‡ç½®å…±äº«å®ä¾‹
    reset_shared_llm()
    shared_llm_3 = get_shared_llm()

    print(f"âœ… é‡ç½®åæ˜¯æ–°å®ä¾‹: {shared_llm_1 is not shared_llm_3}")


def example_6_graph_level_llm():
    """ç¤ºä¾‹ 6: å›¾çº§åˆ«çš„ LLM é…ç½®"""
    print("\nğŸ“ ç¤ºä¾‹ 6: å›¾çº§åˆ« LLM é…ç½®")

    # åˆ›å»ºä¸“é—¨ç”¨äºæŸä¸ªåˆ†æä»»åŠ¡çš„ LLM
    analysis_llm = create_llm(
        temperature=0.4,
        model="deepseek-v3-1-terminus"
    )

    # åˆ›å»ºä½¿ç”¨ç‰¹å®š LLM çš„å›¾
    graph = create_research_graph(analysis_llm)
    print("âœ… åˆ›å»ºä½¿ç”¨ç‰¹å®š LLM çš„å·¥ä½œæµå›¾")

    # è¿™ä¸ªå›¾ä¸­çš„æ‰€æœ‰éœ€è¦ LLM çš„èŠ‚ç‚¹éƒ½ä¼šä½¿ç”¨ analysis_llm


if __name__ == "__main__":
    print("ğŸš€ LLM ç®¡ç†åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)

    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    example_1_basic_usage()
    example_2_custom_llm()
    example_3_creative_llm()
    example_4_ab_testing()
    example_5_shared_llm_management()
    example_6_graph_level_llm()

    print("\nğŸ¯ æ€»ç»“:")
    print("âœ… LLM å®ä¾‹ç°åœ¨å¯ä»¥çµæ´»é…ç½®å’Œç®¡ç†")
    print("âœ… æ”¯æŒä¸åŒåœºæ™¯çš„å‚æ•°ä¼˜åŒ–")
    print("âœ… ä¾¿äºè¿›è¡Œ A/B æµ‹è¯•å’Œæ€§èƒ½è°ƒä¼˜")
    print("âœ… ç»Ÿä¸€çš„ LLM ç®¡ç†ï¼Œé¿å…é‡å¤åˆå§‹åŒ–")