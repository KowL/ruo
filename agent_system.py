# agent_system.py
from typing import TypedDict, Annotated, List, Dict, Literal, Optional
import operator
from langgraph.graph import StateGraph, END
from langchain_community.chat_models import ChatTongyi  # æˆ– ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv
import json
import pandas as pd
import traceback
from pathlib import Path
import os
import pickle
from datetime import datetime

# åŠ è½½å¯†é’¥
load_dotenv()

# å¯¼å…¥å·¥å…·å‡½æ•°
from tools import get_limit_up_stocks, get_lhb_data, get_f10_data_for_stocks, safe_parse_json

# =======================
# ğŸ§  LLM åˆå§‹åŒ–ï¼ˆé€šä¹‰åƒé—®ï¼‰
# =======================
llm = ChatTongyi(
    model="qwen-plus-latest",  # æ¨è qwen-plus æå‡æ¨ç†è´¨é‡
    api_key=os.getenv("DASHSCOPE_API_KEY") or os.getenv("OPENAI_API_KEY"),
    temperature=0.6,
)

# =======================
# ğŸ§¬ å®šä¹‰çŠ¶æ€ï¼ˆStateï¼‰
# =======================
class ResearchState(TypedDict):
    date: str
    raw_limit_ups: List[dict]
    lhb_data: List[dict]
    f10_data: Dict[str, dict]
    data_officer_report: str
    strategist_thinking: str
    risk_controller_alerts: List[str]
    day_trading_coach_advice: List[dict]
    final_report: str
    context_notes: Annotated[List[str], operator.add]
    next_action: Literal[
        "TO_DATA_OFFICER",
        "TO_STRATEGIST",
        "TO_RISK_CONTROLLER",
        "TO_DAY_TRADING_COACH",
        "TO_FINALIZER",
        "FINISH"
    ]
    error: Optional[str]

# =======================
# ğŸ¤– Node 1: æ•°æ®å®˜
# =======================
def node_data_officer(state: ResearchState) -> ResearchState:
    """é‡‡é›†åŸå§‹æ•°æ®"""
    stocks = get_limit_up_stocks(state['date'])
    lhb = get_lhb_data(state['date'])
    f10 = get_f10_data_for_stocks(stocks)

    count = len(stocks)
    concepts = ", ".join(pd.DataFrame(stocks)['æ¦‚å¿µ'].str.split(',').sum()[:10]) if count > 0 else ""

    report = f"ğŸ“Š æ•°æ®å®˜ç®€æŠ¥ï¼š{state['date']} å…± {count} åªä¸ªè‚¡æ¶¨åœã€‚\nä¸»è¦çƒ­ç‚¹æ¦‚å¿µï¼š{concepts}ã€‚"

    return {
        "raw_limit_ups": stocks,
        "lhb_data": lhb,
        "f10_data": f10,
        "data_officer_report": report,
        "context_notes": [f"âœ… æ•°æ®å®˜å®Œæˆï¼Œå…±é‡‡é›† {count} åªæ¶¨åœè‚¡"],
        "next_action": "TO_STRATEGIST"
    }

# =======================
# ğŸ§  Node 2: ç­–ç•¥å¸ˆ
# =======================
def node_strategist(state: ResearchState) -> ResearchState:
    prompt = ChatPromptTemplate.from_template("""
ä½ æ˜¯èµ„æ·±ç­–ç•¥å¸ˆï¼Œè¯·ç»“åˆå½“å‰æ¶¨åœåˆ†å¸ƒã€è¿æ¿æƒ…å†µå’Œå¸‚åœºæƒ…ç»ªï¼Œåˆ¤æ–­ä¸»çº¿æ–¹å‘ä¸æ“ä½œç­–ç•¥ã€‚
è¾“å…¥ä¿¡æ¯ï¼š
- æ¶¨åœæ€»æ•°ï¼š{total}
- è¿æ¿æ•°é‡ï¼š{lianban_count}
- çƒ­ç‚¹æ¦‚å¿µï¼š{top_concepts}

è¯·è¾“å‡ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œæ§åˆ¶åœ¨100å­—ä»¥å†…ã€‚
""")
    chain = prompt | llm

    df = pd.DataFrame(state['raw_limit_ups'])
    lianban_count = len(df[df['è¿ç»­æ¶¨åœå¤©æ•°'] > 1])
    top_concepts = df['æ¦‚å¿µ'].str.split(',').explode().value_counts().head(3).index.tolist()

    resp = chain.invoke({
        "total": len(state['raw_limit_ups']),
        "lianban_count": lianban_count,
        "top_concepts": ", ".join(top_concepts)
    })

    return {
        "strategist_thinking": resp.content.strip(),
        "context_notes": ["ğŸ’¡ ç­–ç•¥å¸ˆå®Œæˆåˆ†æ"],
        "next_action": "TO_RISK_CONTROLLER"
    }

# =======================
# ğŸ›¡ï¸ Node 3: é£æ§å‘˜
# =======================
def node_risk_controller(state: ResearchState) -> ResearchState:
    alerts = []
    df = pd.DataFrame(state['raw_limit_ups'])

    # é«˜ä¼°å€¼æ£€æŸ¥
    high_pe_stocks = df[pd.to_numeric(df['å¸‚ç›ˆç‡-åŠ¨æ€'], errors='coerce') > 150]
    if len(high_pe_stocks) > 0:
        names = ",".join(high_pe_stocks['åç§°'][:3])
        alerts.append(f"âš ï¸ é«˜ä¼°å€¼è­¦ç¤ºï¼š{names} ç­‰ {len(high_pe_stocks)} åªä¸ªè‚¡ PE > 150")

    # æ¿å—è¿‡çƒ­æ£€æŸ¥
    concept_grouped = df['æ¦‚å¿µ'].str.split(',').explode().value_counts()
    overheated = concept_grouped[concept_grouped > 5].index.tolist()
    if overheated:
        alerts.append(f"âš ï¸ æ¿å—è¿‡çƒ­ï¼š'{overheated[0]}' æ¦‚å¿µæœ‰ {concept_grouped[overheated[0]]} åªæ¶¨åœè‚¡ï¼Œæ³¨æ„åˆ†åŒ–é£é™©")

    return {
        "risk_controller_alerts": alerts,
        "context_notes": ["ğŸ›¡ï¸ é£æ§å‘˜å®Œæˆæ‰«æ"] + ([f"ğŸ”´ å‘ç°é£é™©: {a}" for a in alerts] if alerts else []),
        "next_action": "TO_DAY_TRADING_COACH"
    }

# =======================
# ğŸ¥‹ Node 4: æ‰“æ¿æ•™ç»ƒ
# =======================
def node_day_trading_coach(state: ResearchState) -> ResearchState:
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„ã€æ‰“æ¿æ•™ç»ƒã€‘ï¼Œæ“…é•¿è¯†åˆ«å¼ºåŠ¿è‚¡ä¸´ç›˜ä¿¡å·ã€‚
è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œå¯¹ä»Šæ—¥æ¶¨åœè‚¡ä¸­å…·å¤‡æ½œåŠ›çš„æ ‡çš„ç»™å‡ºå…·ä½“æ“ä½œå»ºè®®ã€‚

âš ï¸ å¿…é¡»è¾“å‡ºæ ‡å‡† JSON æ•°ç»„ï¼Œæ¯é¡¹å¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ '600389'ï¼‰
- name: åç§°ï¼ˆå¦‚ 'å‰‘æ¡¥ç§‘æŠ€'ï¼‰
- action: åŠ¨ä½œï¼ˆ"å¯æ‰“æ¿"/"å…³æ³¨"/"è§‚æœ›"/"å›é¿"ï¼‰
- entry_point: ä¹°ç‚¹æè¿°ï¼ˆå¦‚ '9:25é›†åˆç«ä»·'ï¼‰
- stop_loss: æ­¢æŸä»·ï¼ˆå•ä½ï¼šå…ƒï¼‰
- take_profit: ç›®æ ‡ä»·ï¼ˆå•ä½ï¼šå…ƒï¼‰
- risk_reward_ratio: é£é™©æ”¶ç›Šæ¯”ï¼ˆå¦‚ '1:3'ï¼‰
- reason: ä¸è¶…è¿‡50å­—çš„é€»è¾‘è¯´æ˜

ç¤ºä¾‹è¾“å‡ºï¼š
[{"code":"600389","name":"å‰‘æ¡¥ç§‘æŠ€","action":"å¯æ‰“æ¿","entry_point":"9:25é›†åˆç«ä»·","stop_loss":"118.5","take_profit":"140","risk_reward_ratio":"1:3","reason":"CPOé¾™å¤´+æœºæ„åŠ ä»“"}]

åªæ¨èæœ€å¤š 3 åªæœ€æœ‰æŠŠæ¡çš„è‚¡ç¥¨ã€‚
ä¸å¾—æ¨è ST è‚¡æˆ– PE > 200 çš„ä¸ªè‚¡ã€‚
""")
    ])

    # æ„å»ºå€™é€‰æ± 
    candidates = []
    for s in state['raw_limit_ups']:
        code = s['ä»£ç ']
        name = s['åç§°']
        if 'ST' in name:
            continue
        pe = (state['f10_data'].get(code) or {}).get('pe', None)
        if isinstance(pe, (int, float)) and (pe or 0) > 200:
            continue

        yoyou_buy_in = False
        top_keywords = ["å›½ç››è¯åˆ¸å®æ³¢æ¡‘ç”°è·¯", "ä¸œæ–¹è´¢å¯Œæ‹‰è¨å›¢ç»“è·¯", "åé‘«è¯åˆ¸ä¸Šæµ·åˆ†å…¬å¸"]
        for item in state['lhb_data']:
            if item.get("è¯åˆ¸ç®€ç§°") == name and any(kw in item.get("ä¹°å…¥æ€»é¢åç§°ä¸è¥ä¸šéƒ¨", "") for kw in top_keywords):
                yoyou_buy_in = True
                break

        candidates.append({
            "code": code,
            "name": name,
            "limit_time": s.get("æ¶¨åœæ—¶é—´", "æœªçŸ¥"),
            "is_lianban": s.get("è¿ç»­æ¶¨åœå¤©æ•°", 0) > 1,
            "turnover_rate": s.get("æ¢æ‰‹ç‡", 0),
            "volume_ratio": s.get("é‡æ¯”", 1.0),
            "concept": s.get("æ¦‚å¿µ", ""),
            "pe": pe,
            "yoyou_buy_in": yoyou_buy_in
        })

    try:
        response = llm.invoke([
            HumanMessage(content=f"å€™é€‰è‚¡:\n{json.dumps(candidates[:10], ensure_ascii=False, indent=2)}\n\nè¯·è¾“å‡ºå»ºè®®")
        ])
        content = response.content.strip()
        advice_list = safe_parse_json(content)
    except Exception as e:
        advice_list = [{"error": str(e), "fallback": "ç”Ÿæˆå¤±è´¥"}]

    return {
        "day_trading_coach_advice": advice_list,
        "context_notes": ["ğŸ¥‹ æ‰“æ¿æ•™ç»ƒæä¾›å»ºè®®"],
        "next_action": "TO_FINALIZER"
    }

# =======================
# ğŸ“ Node 5: æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå™¨
# =======================
def node_finalize_report(state: ResearchState) -> ResearchState:
    coach_advice = [a for a in state.get("day_trading_coach_advice", []) if isinstance(a, dict) and "code" in a]

    coach_summary = "\n".join([
        f"ğŸ¯ {a['name']}({a['code']}): {a['action']} | ä¹°ç‚¹:{a['entry_point']} | ç›®æ ‡:{a.get('take_profit','?')}å…ƒ | R/R:{a.get('risk_reward_ratio','?')}"
        for a in coach_advice[:3]
    ]) if coach_advice else "æš‚æ— æ¨èæ‰“æ¿æ ‡çš„ã€‚"

    summary = f"""
ğŸ¯ã€AIæŠ•ç ”æ—¥æŠ¥ã€‘{state['date']}

ğŸ“Š æ•°æ®å®˜ç®€æŠ¥ï¼š
{state['data_officer_report']}

ğŸ’¡ ç­–ç•¥å¸ˆè§‚ç‚¹ï¼š
{state['strategist_thinking']}

ğŸ›¡ï¸ é£æ§æé†’ï¼š
{' '.join(state['risk_controller_alerts'])}

ğŸ¥‹ æ‰“æ¿æ•™ç»ƒå»ºè®®ï¼š
{coach_summary}

ğŸ“Œ ç»¼åˆå»ºè®®ï¼šçŸ­çº¿é€‰æ‰‹å¯åœ¨æ§åˆ¶ä»“ä½å‰æä¸‹å‚ä¸é«˜ç¡®å®šæ€§æœºä¼šï¼Œä¼˜å…ˆé€‰æ‹©â€œæœºæ„+æ¸¸èµ„â€å…±è¿›å“ç§ï¼Œå›é¿çº¯æƒ…ç»ªåšå‚»æ ‡çš„ã€‚
"""
    return {
        "final_report": summary,
        "context_notes": ["âœ… å…¨æµç¨‹å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"],
        "next_action": "FINISH"
    }

# =======================
# ğŸ§­ æ¡ä»¶è·¯ç”±å‡½æ•°
# =======================
def route_next_step(state: ResearchState) -> str:
    return state["next_action"]

# =======================
# ğŸŒ æ„å»º Graph
# =======================
def create_research_graph():
    workflow = StateGraph(ResearchState)

    # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
    workflow.add_node("node_data_officer", node_data_officer)
    workflow.add_node("node_strategist", node_strategist)
    workflow.add_node("node_risk_controller", node_risk_controller)
    workflow.add_node("node_day_trading_coach", node_day_trading_coach)
    workflow.add_node("node_finalize_report", node_finalize_report)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("node_data_officer")

    # æ·»åŠ æ¡ä»¶è¾¹ï¼ˆCondition Edgeï¼‰
    workflow.add_conditional_edges(
        "node_data_officer",
        route_next_step,
        {
            "TO_STRATEGIST": "node_strategist"
        }
    )
    workflow.add_conditional_edges(
        "node_strategist",
        route_next_step,
        {
            "TO_RISK_CONTROLLER": "node_risk_controller"
        }
    )
    workflow.add_conditional_edges(
        "node_risk_controller",
        route_next_step,
        {
            "TO_DAY_TRADING_COACH": "node_day_trading_coach"
        }
    )
    workflow.add_conditional_edges(
        "node_day_trading_coach",
        route_next_step,
        {
            "TO_FINALIZER": "node_finalize_report"
        }
    )
    workflow.add_conditional_edges(
        "node_finalize_report",
        route_next_step,
        {
            "FINISH": END
        }
    )

    # ç¼–è¯‘å›¾
    app = workflow.compile()
    return app

# === ç¼“å­˜é…ç½® ===
CACHE_DIR = Path("cache/daily_research")
CACHE_DIR.mkdir(parents=True, exist_ok=True)

# æ–°å¢å‡½æ•°ï¼šä¿å­˜æŠ¥å‘Šåˆ°æœ¬åœ°
def save_report_to_cache(state: dict, date: str):
    """å°†åˆ†æç»“æœæŒä¹…åŒ–åˆ°æœ¬åœ°ç¼“å­˜"""
    # åˆ›å»ºæ—¥æœŸå­ç›®å½•
    date_dir = CACHE_DIR / date
    date_dir.mkdir(exist_ok=True)

    # ä¿å­˜å®Œæ•´çŠ¶æ€ï¼ˆç”¨äºè°ƒè¯•å’Œåç»­å·¥ä½œæµï¼‰
    state_path = date_dir / "state.json"
    with open(state_path, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2, default=str)

    # ç”Ÿæˆå¹¶ä¿å­˜ Markdown æŠ¥å‘Šï¼ˆç»™äººçœ‹ï¼‰
    md_content = f"""
# ğŸ“Š AIæŠ•ç ”æ—¥æŠ¥ï¼š{date}

ğŸ“… åˆ†ææ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
{'-'*50}

## ğŸ“ˆ æ•°æ®å®˜ç®€æŠ¥
{state.get('data_officer_report', 'æ— ')}

## ğŸ’¡ ç­–ç•¥å¸ˆè§‚ç‚¹
> {state.get('strategist_thinking', 'æ— ')}

## ğŸ›¡ï¸ é£æ§æé†’
"""
    for alert in state.get("risk_controller_alerts", []):
        md_content += f"- {alert}\n"

    md_content += "\n## ğŸ¥‹ æ‰“æ¿æ•™ç»ƒå»ºè®®\n"
    for item in state.get("day_trading_coach_advice", []):
        if isinstance(item, dict) and "name" in item:
            md_content += f"""
### {item['name']} ({item['code']})
- **æ“ä½œå»ºè®®**ï¼š{item['action']}
- **ç†æƒ³ä¹°ç‚¹**ï¼š{item['entry_point']}
- **æ­¢æŸä»·**ï¼š{item.get('stop_loss', '?')} å…ƒ
- **ç›®æ ‡ä»·**ï¼š{item.get('take_profit', '?')} å…ƒ
- **é£é™©æ”¶ç›Šæ¯”**ï¼š{item.get('risk_reward_ratio', '?')}
- **é€»è¾‘**ï¼š{item['reason']}
"""

    md_content += f"\n\n---\nğŸ“Œ ç»¼åˆå»ºè®®ï¼šçŸ­çº¿é€‰æ‰‹å¯åœ¨æ§åˆ¶ä»“ä½å‰æä¸‹å‚ä¸é«˜ç¡®å®šæ€§æœºä¼š..."

    md_path = date_dir / "report.md"
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(md_content.strip())

    # ï¼ˆå¯é€‰ï¼‰ä¿å­˜åŸå§‹æ•°æ®
    if "raw_limit_ups" in state:
        pkl_path = date_dir / "raw_data.pkl"
        with open(pkl_path, "wb") as f:
            pickle.dump(pd.DataFrame(state["raw_limit_ups"]), f)

    print(f"âœ… æŠ¥å‘Šå·²ç¼“å­˜è‡³: {date_dir}")

# æ–°å¢å‡½æ•°ï¼šæ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜
def is_cached(date: str) -> bool:
    """åˆ¤æ–­æŸæ—¥çš„åˆ†ææŠ¥å‘Šæ˜¯å¦å·²å­˜åœ¨"""
    date_dir = CACHE_DIR / date
    return date_dir.exists() and (date_dir / "report.md").exists()

# ä¸»å…¥å£å‡½æ•°ï¼šæ”¯æŒç¼“å­˜è¯»å–ä¸å†™å…¥
def run_ai_research_analysis(date: str, force_rerun: bool = False) -> Dict:
    """
    å¯åŠ¨å®Œæ•´çš„ LangGraph å¤š Agent åˆ†ææµç¨‹
    æ”¯æŒç¼“å­˜æœºåˆ¶ï¼šè‹¥å·²å­˜åœ¨ä¸”æœªå¼ºåˆ¶é‡è·‘ï¼Œåˆ™ç›´æ¥è¿”å›ç¼“å­˜ç»“æœ
    """
    cache_file = CACHE_DIR / date / "state.json"

    # âœ… æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
    if not force_rerun and is_cached(date):
        try:
            with open(cache_file, "r", encoding="utf-8") as f:
                cached_state = json.load(f)
            return {
                "success": True,
                "result": cached_state,
                "cached": True,
                "message": f"ä½¿ç”¨ç¼“å­˜ç»“æœï¼ˆ{date}ï¼‰"
            }
        except Exception as e:
            print(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}")

    # ğŸ” å¦åˆ™æ‰§è¡Œå®Œæ•´åˆ†ææµç¨‹
    try:
        graph = create_research_graph()
        initial_state = {
            "date": date,
            "raw_limit_ups": [],
            "lhb_data": [],
            "f10_data": {},
            "context_notes": [],
            "next_action": "TO_DATA_OFFICER"
        }

        final_state = None
        for output in graph.stream(initial_state):
            final_state = output.get(END, output)

        if final_state is None:
            raise ValueError("å›¾æ‰§è¡Œæœªäº§ç”Ÿä»»ä½•è¾“å‡º")

        # âœ… æ‰§è¡Œå®Œæˆåç«‹å³ç¼“å­˜
        save_report_to_cache(final_state, date)

        return {
            "success": True,
            "result": final_state,
            "cached": False,
            "message": f"æ–°ç”ŸæˆæŠ¥å‘Šå¹¶å·²ç¼“å­˜"
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }
