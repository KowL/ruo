# agent_system.py
from typing import TypedDict, Annotated, List, Dict, Literal, Optional
import operator
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import create_react_agent
from langchain_community.chat_models import ChatTongyi  # æˆ– ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.tools import Tool
from dotenv import load_dotenv
import json
import pandas as pd
import traceback
from pathlib import Path
import os
import pickle
from datetime import datetime

# åŠ è½½å¯†é’¥
load_dotenv()

# å¯¼å…¥å·¥å…·å‡½æ•°
from tools import get_limit_up_stocks, get_lhb_data, get_f10_data_for_stocks, safe_parse_json

# =======================
# ğŸ§  LLM åˆå§‹åŒ–ï¼ˆé€šä¹‰åƒé—®ï¼‰
# =======================
llm = ChatTongyi(
    model="qwen-plus-latest",  # æ¨è qwen-plus æå‡æ¨ç†è´¨é‡
    api_key=os.getenv("DASHSCOPE_API_KEY") or os.getenv("OPENAI_API_KEY"),
    temperature=0.6,
)

# =======================
# ğŸ§¬ å®šä¹‰çŠ¶æ€ï¼ˆStateï¼‰
# =======================
class ResearchState(TypedDict):
    date: str
    raw_limit_ups: List[dict]
    lhb_data: List[dict]
    f10_data: Dict[str, dict]
    data_officer_report: str
    strategist_thinking: str
    risk_controller_alerts: List[str]
    day_trading_coach_advice: List[dict]
    final_report: str
    context_notes: Annotated[List[str], operator.add]
    next_action: Literal[
        "TO_DATA_OFFICER",
        "TO_STRATEGIST",
        "TO_RISK_CONTROLLER",
        "TO_DAY_TRADING_COACH",
        "TO_FINALIZER",
        "FINISH"
    ]
    error: Optional[str]

# =======================
# ğŸ¤– Node 1: æ•°æ®å®˜
# =======================
def node_data_officer(state: ResearchState) -> ResearchState:
    """é‡‡é›†åŸå§‹æ•°æ®"""
    stocks = get_limit_up_stocks(state['date'])
    lhb = get_lhb_data(state['date'])
    f10 = get_f10_data_for_stocks(stocks)

    count = len(stocks)
    # ä½¿ç”¨å®é™…çš„åˆ—å 'æ‰€å±è¡Œä¸š' è€Œä¸æ˜¯ 'æ¦‚å¿µ'
    concepts = ", ".join(pd.DataFrame(stocks)['æ‰€å±è¡Œä¸š'].value_counts().head(10).index.tolist()) if count > 0 else ""

    report = f"ğŸ“Š æ•°æ®å®˜ç®€æŠ¥ï¼š{state['date']} å…± {count} åªä¸ªè‚¡æ¶¨åœã€‚\nä¸»è¦çƒ­ç‚¹æ¦‚å¿µï¼š{concepts}ã€‚"

    return {
        "raw_limit_ups": stocks,
        "lhb_data": lhb,
        "f10_data": f10,
        "data_officer_report": report,
        "context_notes": [f"âœ… æ•°æ®å®˜å®Œæˆï¼Œå…±é‡‡é›† {count} åªæ¶¨åœè‚¡"],
        "next_action": "TO_STRATEGIST"
    }

# =======================
# ğŸ§  Node 2: ç­–ç•¥å¸ˆ
# =======================
def node_strategist(state: ResearchState) -> ResearchState:
    prompt = ChatPromptTemplate.from_template("""
ä½ æ˜¯èµ„æ·±ç­–ç•¥å¸ˆï¼Œè¯·ç»“åˆå½“å‰æ¶¨åœåˆ†å¸ƒã€è¿æ¿æƒ…å†µå’Œå¸‚åœºæƒ…ç»ªï¼Œåˆ¤æ–­ä¸»çº¿æ–¹å‘ä¸æ“ä½œç­–ç•¥ã€‚
è¾“å…¥ä¿¡æ¯ï¼š
- æ¶¨åœæ€»æ•°ï¼š{total}
- è¿æ¿æ•°é‡ï¼š{lianban_count}
- çƒ­ç‚¹æ¦‚å¿µï¼š{top_concepts}

è¯·è¾“å‡ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œæ§åˆ¶åœ¨100å­—ä»¥å†…ã€‚
""")
    chain = prompt | llm

    df = pd.DataFrame(state['raw_limit_ups'])
    # ä½¿ç”¨å®é™…çš„åˆ—å 'è¿æ¿æ•°'
    lianban_count = len(df[df['è¿æ¿æ•°'] > 1]) if 'è¿æ¿æ•°' in df.columns else 0
    # ä½¿ç”¨å®é™…çš„åˆ—å 'æ‰€å±è¡Œä¸š'
    top_concepts = df['æ‰€å±è¡Œä¸š'].value_counts().head(3).index.tolist()

    resp = chain.invoke({
        "total": len(state['raw_limit_ups']),
        "lianban_count": lianban_count,
        "top_concepts": ", ".join(top_concepts)
    })

    return {
        "strategist_thinking": resp.content.strip(),
        "context_notes": ["ğŸ’¡ ç­–ç•¥å¸ˆå®Œæˆåˆ†æ"],
        "next_action": "TO_RISK_CONTROLLER"
    }

# =======================
# ğŸ›¡ï¸ Node 3: é£æ§å‘˜
# =======================
def node_risk_controller(state: ResearchState) -> ResearchState:
    alerts = []
    df = pd.DataFrame(state['raw_limit_ups'])

    # é«˜ä¼°å€¼æ£€æŸ¥ - ä½¿ç”¨ f10_data ä¸­çš„å¸‚ç›ˆç‡ä¿¡æ¯
    high_pe_stocks = []
    f10_data = state.get('f10_data', {})
    
    if f10_data:  # åªæœ‰å½“F10æ•°æ®å­˜åœ¨æ—¶æ‰è¿›è¡Œæ£€æŸ¥
        for _, row in df.iterrows():
            code = row['ä»£ç ']
            name = row['åç§°']
            pe_info = f10_data.get(code, {})
            pe = pe_info.get('pe')
            
            if isinstance(pe, (int, float)) and pe > 150:
                high_pe_stocks.append(name)
        
        if len(high_pe_stocks) > 0:
            names = ",".join(high_pe_stocks[:3])
            alerts.append(f"âš ï¸ é«˜ä¼°å€¼è­¦ç¤ºï¼š{names} ç­‰ {len(high_pe_stocks)} åªä¸ªè‚¡ PE > 150")
    else:
        # å¦‚æœæ²¡æœ‰F10æ•°æ®ï¼Œå¯ä»¥åŸºäºå…¶ä»–æŒ‡æ ‡è¿›è¡Œé£é™©æç¤º
        if len(df) > 50:  # å¦‚æœæ¶¨åœè‚¡æ•°é‡è¿‡å¤š
            alerts.append("âš ï¸ å¸‚åœºè¿‡çƒ­ï¼šæ¶¨åœè‚¡æ•°é‡è¿‡å¤šï¼Œæ³¨æ„è¿½é«˜é£é™©")

    # æ¿å—è¿‡çƒ­æ£€æŸ¥ - ä½¿ç”¨å®é™…çš„åˆ—å 'æ‰€å±è¡Œä¸š'
    if 'æ‰€å±è¡Œä¸š' in df.columns:
        concept_grouped = df['æ‰€å±è¡Œä¸š'].value_counts()
        overheated = concept_grouped[concept_grouped > 5].index.tolist()
        if overheated:
            alerts.append(f"âš ï¸ æ¿å—è¿‡çƒ­ï¼š'{overheated[0]}' è¡Œä¸šæœ‰ {concept_grouped[overheated[0]]} åªæ¶¨åœè‚¡ï¼Œæ³¨æ„åˆ†åŒ–é£é™©")

    return {
        "risk_controller_alerts": alerts,
        "context_notes": ["ğŸ›¡ï¸ é£æ§å‘˜å®Œæˆæ‰«æ"] + ([f"ğŸ”´ å‘ç°é£é™©: {a}" for a in alerts] if alerts else []),
        "next_action": "TO_DAY_TRADING_COACH"
    }

# =======================
# ğŸ› ï¸ æ‰“æ¿æ•™ç»ƒåˆ†æå·¥å…·
# =======================
def analyze_lhb_data(lhb_data_json: str) -> str:
    """åˆ†æé¾™è™æ¦œæ•°æ®ï¼Œè¯†åˆ«ä¸»åŠ›èµ„é‡‘åŠ¨å‘"""
    try:
        lhb_data = json.loads(lhb_data_json) if isinstance(lhb_data_json, str) else lhb_data_json
        
        if not lhb_data:
            return "é¾™è™æ¦œæ•°æ®ä¸ºç©ºï¼Œæ— æ³•åˆ†æä¸»åŠ›èµ„é‡‘åŠ¨å‘"
        
        analysis = []
        analysis.append(f"ğŸ“Š é¾™è™æ¦œæ•°æ®åˆ†æï¼ˆå…±{len(lhb_data)}æ¡è®°å½•ï¼‰ï¼š")
        
        # åˆ†æå‡€ä¹°å…¥é‡‘é¢æ’å
        net_buy_stocks = []
        for item in lhb_data[:10]:  # åªåˆ†æå‰10æ¡
            name = item.get('åç§°', '')
            net_buy = item.get('é¾™è™æ¦œå‡€ä¹°é¢', 0)
            reason = item.get('ä¸Šæ¦œåŸå› ', '')
            explanation = item.get('è§£è¯»', '')
            
            net_buy_stocks.append({
                'name': name,
                'net_buy': net_buy,
                'reason': reason,
                'explanation': explanation
            })
        
        # æŒ‰å‡€ä¹°å…¥é‡‘é¢æ’åº
        net_buy_stocks.sort(key=lambda x: x['net_buy'], reverse=True)
        
        analysis.append("\nğŸ”¥ ä¸»åŠ›èµ„é‡‘å‡€ä¹°å…¥TOP5ï¼š")
        for i, stock in enumerate(net_buy_stocks[:5]):
            if stock['net_buy'] > 0:
                analysis.append(f"{i+1}. {stock['name']}: +{stock['net_buy']/10000:.0f}ä¸‡å…ƒ ({stock['explanation']})")
        
        analysis.append("\nğŸ“‰ ä¸»åŠ›èµ„é‡‘å‡€å–å‡ºTOP3ï¼š")
        negative_stocks = [s for s in net_buy_stocks if s['net_buy'] < 0]
        for i, stock in enumerate(negative_stocks[:3]):
            analysis.append(f"{i+1}. {stock['name']}: {stock['net_buy']/10000:.0f}ä¸‡å…ƒ ({stock['explanation']})")
        
        return "\n".join(analysis)
        
    except Exception as e:
        return f"é¾™è™æ¦œæ•°æ®åˆ†æå¤±è´¥: {str(e)}"

def analyze_candidate_stocks(candidates_json: str) -> str:
    """åˆ†æå€™é€‰è‚¡ç¥¨æ± ï¼Œç­›é€‰ä¼˜è´¨æ ‡çš„"""
    try:
        candidates = json.loads(candidates_json) if isinstance(candidates_json, str) else candidates_json
        
        if not candidates:
            return "å€™é€‰è‚¡ç¥¨æ± ä¸ºç©º"
        
        analysis = []
        analysis.append(f"ğŸ¯ å€™é€‰è‚¡ç¥¨åˆ†æï¼ˆå…±{len(candidates)}åªï¼‰ï¼š")
        
        # æŒ‰è¿æ¿æ•°æ’åº
        lianban_stocks = [c for c in candidates if c.get('is_lianban', False)]
        analysis.append(f"\nğŸš€ è¿æ¿è‚¡ï¼ˆ{len(lianban_stocks)}åªï¼‰ï¼š")
        
        lianban_stocks.sort(key=lambda x: x.get('turnover_rate', 0), reverse=True)
        for i, stock in enumerate(lianban_stocks[:5]):
            analysis.append(f"{i+1}. {stock['name']}({stock['code']}): æ¢æ‰‹ç‡{stock.get('turnover_rate', 0):.1f}%, è¡Œä¸š:{stock.get('concept', '')}")
        
        # é«˜æ¢æ‰‹ç‡è‚¡ç¥¨
        high_turnover = [c for c in candidates if c.get('turnover_rate', 0) > 10]
        analysis.append(f"\nğŸ’« é«˜æ¢æ‰‹ç‡è‚¡ç¥¨ï¼ˆ>10%, å…±{len(high_turnover)}åªï¼‰ï¼š")
        
        high_turnover.sort(key=lambda x: x.get('turnover_rate', 0), reverse=True)
        for i, stock in enumerate(high_turnover[:5]):
            analysis.append(f"{i+1}. {stock['name']}({stock['code']}): {stock.get('turnover_rate', 0):.1f}%")
        
        # è¡Œä¸šåˆ†å¸ƒ
        industries = {}
        for stock in candidates:
            industry = stock.get('concept', 'æœªçŸ¥')
            industries[industry] = industries.get(industry, 0) + 1
        
        analysis.append(f"\nğŸ­ è¡Œä¸šåˆ†å¸ƒï¼š")
        sorted_industries = sorted(industries.items(), key=lambda x: x[1], reverse=True)
        for industry, count in sorted_industries[:5]:
            analysis.append(f"- {industry}: {count}åª")
        
        return "\n".join(analysis)
        
    except Exception as e:
        return f"å€™é€‰è‚¡ç¥¨åˆ†æå¤±è´¥: {str(e)}"

def get_stock_lhb_data(stock_info_json: str) -> str:
    """è·å–ç‰¹å®šè‚¡ç¥¨çš„é¾™è™æ¦œæ•°æ®
    
    å‚æ•°æ ¼å¼: JSONå­—ç¬¦ä¸²ï¼ŒåŒ…å«è‚¡ç¥¨ä»£ç å’Œåç§°
    ä¾‹å¦‚: '{"code": "000001", "name": "å¹³å®‰é“¶è¡Œ", "date": "2025-11-26"}'
    """
    try:
        if isinstance(stock_info_json, str):
            stock_info = json.loads(stock_info_json)
        else:
            stock_info = stock_info_json
            
        code = stock_info.get('code', '')
        name = stock_info.get('name', '')
        date = stock_info.get('date', '')
        
        if not code or not name:
            return f"âŒ è‚¡ç¥¨ä¿¡æ¯ä¸å®Œæ•´: {stock_info}"
        
        # ä»å…¨å±€é¾™è™æ¦œæ•°æ®ä¸­æŸ¥æ‰¾è¯¥è‚¡ç¥¨çš„è®°å½•
        # è¿™é‡Œéœ€è¦è®¿é—®stateä¸­çš„lhb_dataï¼Œæˆ‘ä»¬é€šè¿‡å…¨å±€å˜é‡ä¼ é€’
        global current_lhb_data
        if not hasattr(get_stock_lhb_data, 'lhb_data'):
            return f"âš ï¸ {name}({code}) æœªæ‰¾åˆ°é¾™è™æ¦œæ•°æ®"
            
        lhb_data = getattr(get_stock_lhb_data, 'lhb_data', [])
        
        # æŸ¥æ‰¾è¯¥è‚¡ç¥¨çš„é¾™è™æ¦œè®°å½•
        stock_lhb_records = []
        for record in lhb_data:
            if (record.get('ä»£ç ') == code or 
                record.get('åç§°') == name or 
                name in record.get('åç§°', '')):
                stock_lhb_records.append(record)
        
        if not stock_lhb_records:
            return f"âš ï¸ {name}({code}) æœªä¸Šé¾™è™æ¦œ"
        
        # åˆ†æè¯¥è‚¡ç¥¨çš„é¾™è™æ¦œæ•°æ®
        analysis = []
        analysis.append(f"ğŸ¯ {name}({code}) é¾™è™æ¦œåˆ†æï¼š")
        
        for i, record in enumerate(stock_lhb_records):
            net_buy = record.get('é¾™è™æ¦œå‡€ä¹°é¢', 0)
            buy_amount = record.get('é¾™è™æ¦œä¹°å…¥é¢', 0)
            sell_amount = record.get('é¾™è™æ¦œå–å‡ºé¢', 0)
            reason = record.get('ä¸Šæ¦œåŸå› ', '')
            explanation = record.get('è§£è¯»', '')
            
            analysis.append(f"\nğŸ“Š è®°å½•{i+1}:")
            analysis.append(f"- ä¸Šæ¦œåŸå› : {reason}")
            analysis.append(f"- å‡€ä¹°å…¥: {net_buy/10000:.0f}ä¸‡å…ƒ")
            analysis.append(f"- ä¹°å…¥é¢: {buy_amount/10000:.0f}ä¸‡å…ƒ")
            analysis.append(f"- å–å‡ºé¢: {sell_amount/10000:.0f}ä¸‡å…ƒ")
            analysis.append(f"- å¸‚åœºè§£è¯»: {explanation}")
            
            # åˆ¤æ–­ä¸»åŠ›èµ„é‡‘æ€åº¦
            if net_buy > 0:
                attitude = "çœ‹å¤š" if net_buy > buy_amount * 0.3 else "æ¸©å’Œçœ‹å¤š"
            elif net_buy < 0:
                attitude = "çœ‹ç©º" if abs(net_buy) > sell_amount * 0.3 else "æ¸©å’Œçœ‹ç©º"
            else:
                attitude = "ä¸­æ€§"
            analysis.append(f"- ä¸»åŠ›æ€åº¦: {attitude}")
        
        return "\n".join(analysis)
        
    except Exception as e:
        return f"è·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {str(e)}"

def calculate_risk_reward(stock_data_json: str) -> str:
    """è®¡ç®—é£é™©æ”¶ç›Šæ¯”å’Œä¹°å–ç‚¹ï¼ŒåŒ…æ‹¬æ­¢æŸä»·å’Œç›®æ ‡ä»·
    
    å‚æ•°æ ¼å¼: JSONå­—ç¬¦ä¸²ï¼ŒåŒ…å«è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    ä¾‹å¦‚: '{"code": "000001", "name": "å¹³å®‰é“¶è¡Œ", "turnover_rate": 5.2, "pe": 6.5, "current_price": 10.5}'
    
    è¿”å›æ ¼å¼: JSONå­—ç¬¦ä¸²ï¼ŒåŒ…å«æ­¢æŸä»·ã€ç›®æ ‡ä»·å’Œé£é™©æ”¶ç›Šæ¯”
    """
    try:
        if isinstance(stock_data_json, str):
            stock_data = json.loads(stock_data_json)
        else:
            # å¦‚æœä¼ å…¥çš„ä¸æ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨
            stock_data = stock_data_json
        
        name = stock_data.get('name', 'æœªçŸ¥è‚¡ç¥¨')
        code = stock_data.get('code', '')
        current_price = float(stock_data.get('current_price', 0))
        
        # å¦‚æœæ²¡æœ‰ä»·æ ¼ä¿¡æ¯ï¼Œè¿”å›é”™è¯¯
        if current_price <= 0:
            return json.dumps({
                "code": code,
                "name": name,
                "stop_loss": 0,
                "take_profit": 0,
                "risk_reward_ratio": 0,
                "error": "ç¼ºå°‘ä»·æ ¼ä¿¡æ¯ï¼Œæ— æ³•è®¡ç®—æ­¢æŸä»·å’Œç›®æ ‡ä»·"
            }, ensure_ascii=False)
        
        # åŸºäºæ¢æ‰‹ç‡å’ŒPEä¼°ç®—é£é™©ç­‰çº§
        turnover = float(stock_data.get('turnover_rate', 0))
        pe = stock_data.get('pe')
        
        if turnover > 15:
            risk_level = "é«˜é£é™©"
            risk_score = 3
            # é«˜é£é™©ï¼šæ­¢æŸå¹…åº¦æ›´å¤§ï¼ˆ-8%ï¼‰ï¼Œç›®æ ‡ä»·æ›´ä¿å®ˆï¼ˆ+10%ï¼‰
            stop_loss_pct = -0.08
            take_profit_pct = 0.10
        elif turnover > 8:
            risk_level = "ä¸­é£é™©"
            risk_score = 2
            # ä¸­é£é™©ï¼šæ­¢æŸ-5%ï¼Œç›®æ ‡+15%
            stop_loss_pct = -0.05
            take_profit_pct = 0.15
        else:
            risk_level = "ä½é£é™©"
            risk_score = 1
            # ä½é£é™©ï¼šæ­¢æŸ-3%ï¼Œç›®æ ‡+20%
            stop_loss_pct = -0.03
            take_profit_pct = 0.20
        
        # æ ¹æ®PEè°ƒæ•´ç›®æ ‡ä»·
        if pe and pe > 0:
            if pe > 100:
                valuation = "é«˜ä¼°"
                val_score = 3
                # é«˜ä¼°å€¼ï¼šé™ä½ç›®æ ‡ä»·
                take_profit_pct *= 0.7
            elif pe > 30:
                valuation = "åˆç†"
                val_score = 2
                # åˆç†ä¼°å€¼ï¼šä¿æŒç›®æ ‡ä»·
            else:
                valuation = "ä½ä¼°"
                val_score = 1
                # ä½ä¼°å€¼ï¼šæé«˜ç›®æ ‡ä»·
                take_profit_pct *= 1.2
        else:
            valuation = "æ— æ³•è¯„ä¼°"
            val_score = 2
        
        # è®¡ç®—æ­¢æŸä»·å’Œç›®æ ‡ä»·
        stop_loss = round(current_price * (1 + stop_loss_pct), 2)
        take_profit = round(current_price * (1 + take_profit_pct), 2)
        
        # è®¡ç®—é£é™©æ”¶ç›Šæ¯”
        risk = current_price - stop_loss
        reward = take_profit - current_price
        risk_reward_ratio = round(reward / risk, 2) if risk > 0 else 0
        
        # è¿”å›JSONæ ¼å¼çš„ç»“æœ
        result = {
            "code": code,
            "name": name,
            "current_price": current_price,
            "stop_loss": stop_loss,
            "take_profit": take_profit,
            "risk_reward_ratio": risk_reward_ratio,
            "risk_level": risk_level,
            "valuation": valuation,
            "analysis": f"é£é™©ç­‰çº§: {risk_level}, ä¼°å€¼: {valuation}, æ¢æ‰‹ç‡: {turnover:.1f}%"
        }
        
        return json.dumps(result, ensure_ascii=False)
        
    except Exception as e:
        return json.dumps({
            "error": f"é£é™©æ”¶ç›Šåˆ†æå¤±è´¥: {str(e)}",
            "stop_loss": 0,
            "take_profit": 0,
            "risk_reward_ratio": 0
        }, ensure_ascii=False)

# åˆ›å»ºå·¥å…·åˆ—è¡¨
coach_tools = [
    Tool(
        name="analyze_candidate_stocks", 
        func=analyze_candidate_stocks,
        description="åˆ†æå€™é€‰è‚¡ç¥¨æ± ï¼Œç­›é€‰è¿æ¿è‚¡ã€é«˜æ¢æ‰‹ç‡è‚¡ç¥¨å’Œå¼ºåŠ¿æ¿å—ã€‚è¾“å…¥ï¼šå€™é€‰è‚¡ç¥¨æ•°æ®çš„JSONå­—ç¬¦ä¸²ã€‚è¿™åº”è¯¥æ˜¯ä½ çš„ç¬¬ä¸€æ­¥åˆ†æã€‚"
    ),
    Tool(
        name="get_stock_lhb_data",
        func=get_stock_lhb_data,
        description="è·å–ç‰¹å®šè‚¡ç¥¨çš„é¾™è™æ¦œæ•°æ®å’Œä¸»åŠ›èµ„é‡‘åˆ†æã€‚è¾“å…¥ï¼šè‚¡ç¥¨ä¿¡æ¯JSONå­—ç¬¦ä¸²ï¼Œæ ¼å¼å¦‚'{\"code\":\"000001\",\"name\":\"å¹³å®‰é“¶è¡Œ\",\"date\":\"2025-11-26\"}'"
    ),
    Tool(
        name="calculate_risk_reward",
        func=calculate_risk_reward,
        description="è®¡ç®—ä¸ªè‚¡çš„é£é™©æ”¶ç›Šæ¯”ã€æ­¢æŸä»·å’Œç›®æ ‡ä»·ã€‚è¾“å…¥ï¼šå•ä¸ªè‚¡ç¥¨æ•°æ®çš„JSONå­—ç¬¦ä¸²ï¼Œå¿…é¡»åŒ…å«current_priceå­—æ®µï¼Œæ ¼å¼å¦‚'{\"code\":\"000001\",\"name\":\"å¹³å®‰é“¶è¡Œ\",\"turnover_rate\":5.2,\"pe\":6.5,\"current_price\":10.5}'ã€‚è¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«stop_lossï¼ˆæ­¢æŸä»·ï¼‰ã€take_profitï¼ˆç›®æ ‡ä»·ï¼‰å’Œrisk_reward_ratioï¼ˆé£é™©æ”¶ç›Šæ¯”ï¼‰å­—æ®µã€‚"
    ),
    Tool(
        name="analyze_lhb_data",
        func=analyze_lhb_data,
        description="åˆ†ææ•´ä½“é¾™è™æ¦œæ•°æ®ï¼Œè¯†åˆ«å¸‚åœºä¸»åŠ›èµ„é‡‘åŠ¨å‘ã€‚è¾“å…¥ï¼šé¾™è™æ¦œæ•°æ®çš„JSONå­—ç¬¦ä¸²ã€‚ç”¨äºäº†è§£æ•´ä½“å¸‚åœºæƒ…å†µã€‚"
    )
]

# =======================
# ğŸ¥‹ Node 4: æ‰“æ¿æ•™ç»ƒ (ReAct Agentä¼˜åŒ–ç‰ˆ)
# =======================
def node_day_trading_coach(state: ResearchState) -> ResearchState:
    """ä½¿ç”¨ReAct Agentçš„æ‰“æ¿æ•™ç»ƒï¼Œè¾“å‡ºè¯¦ç»†æ€è€ƒè¿‡ç¨‹"""
    
    # æ„å»ºå€™é€‰æ± 
    candidates = []
    for s in state['raw_limit_ups']:
        code = s['ä»£ç ']
        name = s['åç§°']
        if 'ST' in name:
            continue
        pe = (state['f10_data'].get(code) or {}).get('pe', None)
        if isinstance(pe, (int, float)) and (pe or 0) > 200:
            continue

        # è·å–ä»·æ ¼ä¿¡æ¯ï¼šä¼˜å…ˆä½¿ç”¨æœ€æ–°ä»·ï¼Œå…¶æ¬¡ä½¿ç”¨f10_dataä¸­çš„close_price
        current_price = s.get("æœ€æ–°ä»·") or (state['f10_data'].get(code) or {}).get('close_price') or 0

        candidates.append({
            "code": code,
            "name": name,
            "limit_time": s.get("é¦–æ¬¡å°æ¿æ—¶é—´", "æœªçŸ¥"),
            "is_lianban": s.get("è¿æ¿æ•°", 0) > 1,
            "turnover_rate": s.get("æ¢æ‰‹ç‡", 0),
            "volume_ratio": 1.0,  # é‡æ¯”åˆ—ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
            "concept": s.get("æ‰€å±è¡Œä¸š", ""),
            "pe": pe,
            "current_price": current_price  # æ·»åŠ å½“å‰ä»·æ ¼
        })

    try:
        # è®¾ç½®å…¨å±€é¾™è™æ¦œæ•°æ®ï¼Œä¾›å·¥å…·å‡½æ•°ä½¿ç”¨
        get_stock_lhb_data.lhb_data = state['lhb_data']
        
        # åˆ›å»ºReAct Agent
        system_prompt = """ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„ã€æ‰“æ¿æ•™ç»ƒã€‘ï¼Œæ“…é•¿è¯†åˆ«å¼ºåŠ¿è‚¡ä¸´ç›˜ä¿¡å·ã€‚

ä½ çš„åˆ†ææµç¨‹ï¼š
1. é¦–å…ˆä½¿ç”¨analyze_candidate_stockså·¥å…·åˆ†æå€™é€‰è‚¡ç¥¨æ± ï¼Œäº†è§£æ•´ä½“æƒ…å†µ
2. å¯¹äºé‡ç‚¹å…³æ³¨çš„è‚¡ç¥¨ï¼Œä½¿ç”¨get_stock_lhb_dataå·¥å…·æŸ¥è¯¢å…¶é¾™è™æ¦œæ•°æ®
3. ä½¿ç”¨calculate_risk_rewardå·¥å…·è®¡ç®—é‡ç‚¹è‚¡ç¥¨çš„é£é™©æ”¶ç›Šæ¯”
4. å¦‚éœ€äº†è§£æ•´ä½“å¸‚åœºæƒ…å†µï¼Œå¯ä½¿ç”¨analyze_lhb_dataå·¥å…·
5. æœ€åç»¼åˆæ‰€æœ‰åˆ†æç»“æœï¼Œç»™å‡ºæœ€ç»ˆçš„æ‰“æ¿å»ºè®®

åˆ†æé‡ç‚¹ï¼š
- ä¼˜å…ˆå…³æ³¨è¿æ¿è‚¡å’Œé«˜æ¢æ‰‹ç‡è‚¡ç¥¨
- å¯¹é‡ç‚¹è‚¡ç¥¨æ·±å…¥åˆ†æå…¶é¾™è™æ¦œæ•°æ®ï¼Œè¯†åˆ«ä¸»åŠ›èµ„é‡‘å‚ä¸æƒ…å†µ
- **é‡è¦**ï¼šå¯¹äºæ¯åªé‡ç‚¹è‚¡ç¥¨ï¼Œå¿…é¡»ä½¿ç”¨calculate_risk_rewardå·¥å…·è®¡ç®—æ­¢æŸä»·å’Œç›®æ ‡ä»·
- calculate_risk_rewardå·¥å…·ä¼šè¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«stop_lossï¼ˆæ­¢æŸä»·ï¼‰ã€take_profitï¼ˆç›®æ ‡ä»·ï¼‰å’Œrisk_reward_ratioï¼ˆé£é™©æ”¶ç›Šæ¯”ï¼‰å­—æ®µ
- ä½ å¿…é¡»ä»å·¥å…·è¿”å›çš„JSONä¸­æå–è¿™äº›å€¼ï¼Œå¹¶åœ¨æœ€ç»ˆè¾“å‡ºä¸­ä½¿ç”¨è¿™äº›å…·ä½“çš„æ•°å€¼
- å¦‚æœå·¥å…·è¿”å›çš„stop_lossæˆ–take_profitä¸º0ï¼Œè¯´æ˜ç¼ºå°‘ä»·æ ¼ä¿¡æ¯ï¼Œä½ åº”è¯¥åœ¨reasonä¸­è¯´æ˜
- ä¼˜å…ˆæ¨èæœ‰ä¸»åŠ›èµ„é‡‘å‚ä¸ä¸”æŠ€æœ¯é¢å¼ºåŠ¿çš„æ ‡çš„
- é’ˆå¯¹æ‰€æœ‰è¿æ¿è‚¡è¾“å‡ºæ“ä½œå»ºè®®

æœ€ç»ˆè¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯JSONæ•°ç»„ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- code: è‚¡ç¥¨ä»£ç 
- name: è‚¡ç¥¨åç§°  
- action: æ“ä½œå»ºè®®ï¼ˆ"å¯æ‰“æ¿"/"å…³æ³¨"/"è§‚æœ›"/"å›é¿"ï¼‰
- entry_point: ä¹°ç‚¹æè¿°
- stop_loss: æ­¢æŸä»·ï¼ˆå¿…é¡»æ˜¯ä»calculate_risk_rewardå·¥å…·è¿”å›çš„æ•°å€¼ï¼Œä¸èƒ½ä¸º0ï¼Œé™¤éç¡®å®ç¼ºå°‘ä»·æ ¼ä¿¡æ¯ï¼‰
- take_profit: ç›®æ ‡ä»·ï¼ˆå¿…é¡»æ˜¯ä»calculate_risk_rewardå·¥å…·è¿”å›çš„æ•°å€¼ï¼Œä¸èƒ½ä¸º0ï¼Œé™¤éç¡®å®ç¼ºå°‘ä»·æ ¼ä¿¡æ¯ï¼‰
- risk_reward_ratio: é£é™©æ”¶ç›Šæ¯”ï¼ˆå¿…é¡»æ˜¯ä»calculate_risk_rewardå·¥å…·è¿”å›çš„æ•°å€¼ï¼‰
- reason: é€»è¾‘è¯´æ˜ï¼ˆä¸è¶…è¿‡30å­—ï¼‰

è¯·å¼€å§‹ä½ çš„åˆ†æã€‚"""

        # åˆ›å»ºReAct Agent
        react_agent = create_react_agent(
            model=llm,
            tools=coach_tools,
            prompt=system_prompt
        )
        
        # å‡†å¤‡è¾“å…¥æ•°æ® - ä¸å†é™åˆ¶æ•°æ®é‡
        candidates_str = json.dumps(candidates, ensure_ascii=False, default=str)
        
        user_query = f"""è¯·åˆ†æä»¥ä¸‹å€™é€‰è‚¡ç¥¨æ± å¹¶ç»™å‡ºæ‰“æ¿å»ºè®®ï¼š

å€™é€‰è‚¡ç¥¨æ± ï¼ˆå…±{len(candidates)}åªï¼‰ï¼š
{candidates_str}

åˆ†ææ—¥æœŸï¼š{state['date']}

è¯·æŒ‰ç…§ä½ çš„åˆ†ææµç¨‹ï¼š
1. å…ˆåˆ†æå€™é€‰è‚¡ç¥¨æ± çš„æ•´ä½“æƒ…å†µ
2. å¯¹é‡ç‚¹è‚¡ç¥¨é€ä¸€æŸ¥è¯¢é¾™è™æ¦œæ•°æ®
3. è®¡ç®—é£é™©æ”¶ç›Šæ¯”
4. ç»™å‡ºæœ€ç»ˆçš„æŠ•èµ„å»ºè®®

æ³¨æ„ï¼šé¾™è™æ¦œæ•°æ®å·²å‡†å¤‡å°±ç»ªï¼Œä½ å¯ä»¥é€šè¿‡get_stock_lhb_dataå·¥å…·æŸ¥è¯¢ä»»ä½•è‚¡ç¥¨çš„é¾™è™æ¦œä¿¡æ¯ã€‚"""

        # æ‰§è¡ŒReAct Agent
        print("ğŸ¤– æ‰“æ¿æ•™ç»ƒå¼€å§‹åˆ†æ...")
        
        response = react_agent.invoke({
            "messages": [HumanMessage(content=user_query)]
        })
        
        # æå–æœ€ç»ˆçš„AIæ¶ˆæ¯
        final_message = ""
        thinking_process = []
        
        for message in response["messages"]:
            if isinstance(message, AIMessage):
                thinking_process.append(f"ğŸ¤” æ€è€ƒ: {message.content}")
                final_message = message.content
        
        # æ‰“å°æ€è€ƒè¿‡ç¨‹
        print("\n" + "="*50)
        print("ğŸ§  æ‰“æ¿æ•™ç»ƒæ€è€ƒè¿‡ç¨‹ï¼š")
        for step in thinking_process:
            print(step)
        print("="*50 + "\n")
        
        # ä»æ¶ˆæ¯å†å²ä¸­æå–å·¥å…·è°ƒç”¨ç»“æœï¼Œæ„å»ºä»·æ ¼ä¿¡æ¯æ˜ å°„
        price_info_map = {}  # {code: {stop_loss, take_profit, risk_reward_ratio}}
        
        for message in response["messages"]:
            # æŸ¥æ‰¾å·¥å…·è°ƒç”¨çš„ç»“æœæ¶ˆæ¯
            if hasattr(message, 'content') and isinstance(message.content, str):
                # å°è¯•ä»å·¥å…·è¿”å›ç»“æœä¸­æå–ä»·æ ¼ä¿¡æ¯
                try:
                    # calculate_risk_rewardå·¥å…·è¿”å›çš„æ˜¯JSONå­—ç¬¦ä¸²
                    if '"stop_loss"' in message.content and '"take_profit"' in message.content:
                        tool_result = safe_parse_json(message.content)
                        if isinstance(tool_result, dict) and 'code' in tool_result:
                            code = tool_result.get('code', '')
                            if code and tool_result.get('stop_loss', 0) > 0:
                                price_info_map[code] = {
                                    'stop_loss': tool_result.get('stop_loss', 0),
                                    'take_profit': tool_result.get('take_profit', 0),
                                    'risk_reward_ratio': tool_result.get('risk_reward_ratio', 0)
                                }
                except:
                    pass
        
        # å°è¯•ä»æœ€ç»ˆæ¶ˆæ¯ä¸­æå–JSON
        advice_list = []
        if final_message:
            # å°è¯•æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\[.*?\]', final_message, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                advice_list = safe_parse_json(json_str)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œå°è¯•è§£ææ•´ä¸ªæ¶ˆæ¯
                advice_list = safe_parse_json(final_message)
        
        # åå¤„ç†ï¼šè¡¥å……ç¼ºå¤±çš„ä»·æ ¼ä¿¡æ¯
        for advice in advice_list:
            if isinstance(advice, dict) and 'code' in advice:
                code = advice.get('code', '')
                # å¦‚æœæ­¢æŸä»·æˆ–ç›®æ ‡ä»·ä¸º0ï¼Œå°è¯•ä»å·¥å…·è°ƒç”¨ç»“æœä¸­è·å–
                if (advice.get('stop_loss', 0) == 0 or advice.get('take_profit', 0) == 0) and code in price_info_map:
                    price_info = price_info_map[code]
                    if advice.get('stop_loss', 0) == 0:
                        advice['stop_loss'] = price_info.get('stop_loss', 0)
                    if advice.get('take_profit', 0) == 0:
                        advice['take_profit'] = price_info.get('take_profit', 0)
                    if advice.get('risk_reward_ratio', 0) == 0:
                        advice['risk_reward_ratio'] = price_info.get('risk_reward_ratio', 0)
                
                # å¦‚æœä»ç„¶æ²¡æœ‰ä»·æ ¼ä¿¡æ¯ï¼Œå°è¯•ä»å€™é€‰æ± ä¸­è·å–å½“å‰ä»·æ ¼å¹¶è®¡ç®—
                if (advice.get('stop_loss', 0) == 0 or advice.get('take_profit', 0) == 0):
                    # ä»å€™é€‰æ± ä¸­æŸ¥æ‰¾è¯¥è‚¡ç¥¨
                    candidate = next((c for c in candidates if c.get('code') == code), None)
                    if candidate and candidate.get('current_price', 0) > 0:
                        current_price = candidate.get('current_price', 0)
                        turnover = candidate.get('turnover_rate', 0)
                        pe = candidate.get('pe')
                        
                        # ä½¿ç”¨ä¸calculate_risk_rewardç›¸åŒçš„é€»è¾‘è®¡ç®—
                        if turnover > 15:
                            stop_loss_pct = -0.08
                            take_profit_pct = 0.10
                        elif turnover > 8:
                            stop_loss_pct = -0.05
                            take_profit_pct = 0.15
                        else:
                            stop_loss_pct = -0.03
                            take_profit_pct = 0.20
                        
                        # æ ¹æ®PEè°ƒæ•´
                        if pe and pe > 100:
                            take_profit_pct *= 0.7
                        elif pe and pe <= 30:
                            take_profit_pct *= 1.2
                        
                        if advice.get('stop_loss', 0) == 0:
                            advice['stop_loss'] = round(current_price * (1 + stop_loss_pct), 2)
                        if advice.get('take_profit', 0) == 0:
                            advice['take_profit'] = round(current_price * (1 + take_profit_pct), 2)
                        if advice.get('risk_reward_ratio', 0) == 0:
                            risk = current_price - advice.get('stop_loss', current_price * 0.05)
                            reward = advice.get('take_profit', current_price * 1.15) - current_price
                            advice['risk_reward_ratio'] = round(reward / risk, 2) if risk > 0 else 0
        
        if not advice_list:
            print("âš ï¸ æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„å»ºè®®ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            advice_list = []
            
    except Exception as e:
        print(f"âŒ ReAct Agentæ‰§è¡Œå¤±è´¥: {e}")
        advice_list = []

    return {
        "day_trading_coach_advice": advice_list,
        "context_notes": ["ğŸ¥‹ æ‰“æ¿æ•™ç»ƒ(ReAct)å®Œæˆæ·±åº¦åˆ†æ"],
        "next_action": "TO_FINALIZER"
    }

# =======================
# ğŸ“ Node 5: æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå™¨
# =======================
def node_finalize_report(state: ResearchState) -> ResearchState:
    coach_advice = [a for a in state.get("day_trading_coach_advice", []) if isinstance(a, dict) and "code" in a]

    # æ ¼å¼åŒ–æ‰“æ¿æ•™ç»ƒå»ºè®®ï¼Œä¸report.mdä¿æŒä¸€è‡´
    if coach_advice:
        coach_summary_parts = []
        for a in coach_advice[:100]:
            stock_summary = f"""
ğŸ¯ {a['name']} ({a['code']})
- **æ“ä½œå»ºè®®**ï¼š{a['action']}
- **ç†æƒ³ä¹°ç‚¹**ï¼š{a['entry_point']}
- **æ­¢æŸä»·**ï¼š{a.get('stop_loss', '?')} å…ƒ
- **ç›®æ ‡ä»·**ï¼š{a.get('take_profit', '?')} å…ƒ
- **é£é™©æ”¶ç›Šæ¯”**ï¼š{a.get('risk_reward_ratio', '?')}
- **é€»è¾‘**ï¼š{a['reason']}"""
            coach_summary_parts.append(stock_summary)
        
        coach_summary = "\n".join(coach_summary_parts)
    else:
        coach_summary = "æš‚æ— æ¨èæ‰“æ¿æ ‡çš„ã€‚"

    summary = f"""
ğŸ¯ã€AIæŠ•ç ”æ—¥æŠ¥ã€‘{state['date']}

ğŸ“Š æ•°æ®å®˜ç®€æŠ¥ï¼š
{state['data_officer_report']}

ğŸ’¡ ç­–ç•¥å¸ˆè§‚ç‚¹ï¼š
{state['strategist_thinking']}

ğŸ›¡ï¸ é£æ§æé†’ï¼š
{' '.join(state['risk_controller_alerts'])}

ğŸ¥‹ æ‰“æ¿æ•™ç»ƒå»ºè®®ï¼š
{coach_summary}

ğŸ“Œ ç»¼åˆå»ºè®®ï¼šçŸ­çº¿é€‰æ‰‹å¯åœ¨æ§åˆ¶ä»“ä½å‰æä¸‹å‚ä¸é«˜ç¡®å®šæ€§æœºä¼šï¼Œä¼˜å…ˆé€‰æ‹©â€œæœºæ„+æ¸¸èµ„â€å…±è¿›å“ç§ï¼Œå›é¿çº¯æƒ…ç»ªåšå‚»æ ‡çš„ã€‚
"""
    return {
        "final_report": summary,
        "context_notes": ["âœ… å…¨æµç¨‹å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"],
        "next_action": "FINISH"
    }

# =======================
# ğŸ§­ æ¡ä»¶è·¯ç”±å‡½æ•°
# =======================
def route_next_step(state: ResearchState) -> str:
    return state["next_action"]

# =======================
# ğŸŒ æ„å»º Graph
# =======================
def create_research_graph():
    workflow = StateGraph(ResearchState)

    # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
    workflow.add_node("node_data_officer", node_data_officer)
    workflow.add_node("node_strategist", node_strategist)
    workflow.add_node("node_risk_controller", node_risk_controller)
    workflow.add_node("node_day_trading_coach", node_day_trading_coach)
    workflow.add_node("node_finalize_report", node_finalize_report)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("node_data_officer")

    # æ·»åŠ æ¡ä»¶è¾¹ï¼ˆCondition Edgeï¼‰
    workflow.add_conditional_edges(
        "node_data_officer",
        route_next_step,
        {
            "TO_STRATEGIST": "node_strategist"
        }
    )
    workflow.add_conditional_edges(
        "node_strategist",
        route_next_step,
        {
            "TO_RISK_CONTROLLER": "node_risk_controller"
        }
    )
    workflow.add_conditional_edges(
        "node_risk_controller",
        route_next_step,
        {
            "TO_DAY_TRADING_COACH": "node_day_trading_coach"
        }
    )
    workflow.add_conditional_edges(
        "node_day_trading_coach",
        route_next_step,
        {
            "TO_FINALIZER": "node_finalize_report"
        }
    )
    workflow.add_conditional_edges(
        "node_finalize_report",
        route_next_step,
        {
            "FINISH": END
        }
    )

    # ç¼–è¯‘å›¾
    app = workflow.compile()
    return app

# === ç¼“å­˜é…ç½® ===
CACHE_DIR = Path("cache/daily_research")
CACHE_DIR.mkdir(parents=True, exist_ok=True)

# æ–°å¢å‡½æ•°ï¼šä¿å­˜æŠ¥å‘Šåˆ°æœ¬åœ°
def save_report_to_cache(state: dict, date: str):
    """å°†åˆ†æç»“æœæŒä¹…åŒ–åˆ°æœ¬åœ°ç¼“å­˜"""
    # åˆ›å»ºæ—¥æœŸå­ç›®å½•
    date_dir = CACHE_DIR / date
    date_dir.mkdir(exist_ok=True)

    # ä¿å­˜å®Œæ•´çŠ¶æ€ï¼ˆç”¨äºè°ƒè¯•å’Œåç»­å·¥ä½œæµï¼‰
    state_path = date_dir / "state.json"
    with open(state_path, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2, default=str)

    # ç”Ÿæˆå¹¶ä¿å­˜ Markdown æŠ¥å‘Šï¼ˆç»™äººçœ‹ï¼‰
    md_content = f"""
# ğŸ“Š AIæŠ•ç ”æ—¥æŠ¥ï¼š{date}

ğŸ“… åˆ†ææ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
{'-'*50}

## ğŸ“ˆ æ•°æ®å®˜ç®€æŠ¥
{state.get('data_officer_report', 'æ— ')}

## ğŸ’¡ ç­–ç•¥å¸ˆè§‚ç‚¹
> {state.get('strategist_thinking', 'æ— ')}

## ğŸ›¡ï¸ é£æ§æé†’
"""
    for alert in state.get("risk_controller_alerts", []):
        md_content += f"- {alert}\n"

    md_content += "\n## ğŸ¥‹ æ‰“æ¿æ•™ç»ƒå»ºè®®\n"
    for item in state.get("day_trading_coach_advice", []):
        if isinstance(item, dict) and "name" in item:
            md_content += f"""
### {item['name']} ({item['code']})
- **æ“ä½œå»ºè®®**ï¼š{item['action']}
- **ç†æƒ³ä¹°ç‚¹**ï¼š{item['entry_point']}
- **æ­¢æŸä»·**ï¼š{item.get('stop_loss', '?')} å…ƒ
- **ç›®æ ‡ä»·**ï¼š{item.get('take_profit', '?')} å…ƒ
- **é£é™©æ”¶ç›Šæ¯”**ï¼š{item.get('risk_reward_ratio', '?')}
- **é€»è¾‘**ï¼š{item['reason']}
"""

    md_content += f"\n\n---\nğŸ“Œ ç»¼åˆå»ºè®®ï¼šçŸ­çº¿é€‰æ‰‹å¯åœ¨æ§åˆ¶ä»“ä½å‰æä¸‹å‚ä¸é«˜ç¡®å®šæ€§æœºä¼š..."

    md_path = date_dir / "report.md"
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(md_content.strip())

    # ï¼ˆå¯é€‰ï¼‰ä¿å­˜åŸå§‹æ•°æ®
    if "raw_limit_ups" in state:
        pkl_path = date_dir / "raw_data.pkl"
        with open(pkl_path, "wb") as f:
            pickle.dump(pd.DataFrame(state["raw_limit_ups"]), f)

    print(f"âœ… æŠ¥å‘Šå·²ç¼“å­˜è‡³: {date_dir}")

# æ–°å¢å‡½æ•°ï¼šæ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜
def is_cached(date: str) -> bool:
    """åˆ¤æ–­æŸæ—¥çš„åˆ†ææŠ¥å‘Šæ˜¯å¦å·²å­˜åœ¨"""
    date_dir = CACHE_DIR / date
    return date_dir.exists() and (date_dir / "report.md").exists()

# ä¸»å…¥å£å‡½æ•°ï¼šæ”¯æŒç¼“å­˜è¯»å–ä¸å†™å…¥
def run_ai_research_analysis(date: str, force_rerun: bool = False) -> Dict:
    """
    å¯åŠ¨å®Œæ•´çš„ LangGraph å¤š Agent åˆ†ææµç¨‹
    æ”¯æŒç¼“å­˜æœºåˆ¶ï¼šè‹¥å·²å­˜åœ¨ä¸”æœªå¼ºåˆ¶é‡è·‘ï¼Œåˆ™ç›´æ¥è¿”å›ç¼“å­˜ç»“æœ
    """
    cache_file = CACHE_DIR / date / "state.json"

    # âœ… æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
    if not force_rerun and is_cached(date):
        try:
            with open(cache_file, "r", encoding="utf-8") as f:
                cached_state = json.load(f)
            return {
                "success": True,
                "result": cached_state,
                "cached": True,
                "message": f"ä½¿ç”¨ç¼“å­˜ç»“æœï¼ˆ{date}ï¼‰"
            }
        except Exception as e:
            print(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}")

    # ğŸ” å¦åˆ™æ‰§è¡Œå®Œæ•´åˆ†ææµç¨‹
    try:
        graph = create_research_graph()
        initial_state = {
            "date": date,
            "raw_limit_ups": [],
            "lhb_data": [],
            "f10_data": {},
            "context_notes": [],
            "next_action": "TO_DATA_OFFICER"
        }

        # æ”¶é›†å®Œæ•´çš„çŠ¶æ€ä¿¡æ¯
        accumulated_state = initial_state.copy()
        
        for output in graph.stream(initial_state):
            # æ›´æ–°ç´¯ç§¯çŠ¶æ€
            for node_name, node_output in output.items():
                if isinstance(node_output, dict):
                    accumulated_state.update(node_output)
            
            # å¦‚æœåˆ°è¾¾ç»ˆç‚¹ï¼Œä¿å­˜æœ€ç»ˆçŠ¶æ€
            if END in output:
                final_state = accumulated_state
                break
        else:
            # å¦‚æœæ²¡æœ‰åˆ°è¾¾ENDï¼Œä½¿ç”¨ç´¯ç§¯çŠ¶æ€
            final_state = accumulated_state

        if final_state is None:
            raise ValueError("å›¾æ‰§è¡Œæœªäº§ç”Ÿä»»ä½•è¾“å‡º")

        # âœ… æ‰§è¡Œå®Œæˆåç«‹å³ç¼“å­˜
        save_report_to_cache(final_state, date)

        return {
            "success": True,
            "result": final_state,
            "cached": False,
            "message": f"æ–°ç”ŸæˆæŠ¥å‘Šå¹¶å·²ç¼“å­˜"
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }
